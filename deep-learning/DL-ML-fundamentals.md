#

# Definition of Done

1. "Why we need this?"
2. "What the output means?"
3. "Can I implement this using libraries?"
4. "When to use this?"

# Math Concept

3Blue1Brown?

## Linear Algebra

Vectors & Matrices Operations

Vector addition, subtraction
Matrix multiplication
Dot products
Matrix transpose
Element-wise operations
Broadcasting in NumPy

### Important Concepts

Eigenvalues & eigenvectors (used in PCA, covariance matrices)
Matrix rank
Matrix inverse
Matrix decomposition basics
Vector spaces and linear transformations

## Calculus

### Derivatives

- Chain rule (crucial for backpropagation)
- Partial derivatives
- Gradients
- Jacobian and Hessian matrices (basic understanding)

1. Derivatives and Differentiation
- Why we need this? Derivatives measure the rate of change. In deep learning, they help determine how a small change in input (like weights in a neural network) affects the output (loss or accuracy).
- What the output means? The output of a derivative is the slope or rate of change at a particular point. It indicates whether increasing a weight will increase or decrease the loss, guiding the model's adjustments during training.
- When to use this? Differentiation is used in backpropagation to calculate gradients, which are then used by optimization algorithms (like gradient descent) to update model parameters.
2. Partial Derivatives
Why we need this? Partial derivatives focus on how a function changes with respect to one variable while keeping others constant. In a neural network with many weights, we need to know the effect of changing each one individually.
What the output means? The output tells us how sensitive the loss is to changes in each parameter. This is key for figuring out the most effective direction to adjust each weight to reduce loss.
When to use this? Partial derivatives are calculated for each weight in the network during backpropagation to understand the impact of each one separately.
3. Chain Rule
- Why we need this? The chain rule allows us to compute the derivative of composite functions, which is essential in deep learning because a neural network is essentially a series of nested functions.
- What the output means? The output of the chain rule helps in breaking down the gradient calculation across layers in the network, ensuring each layerâ€™s impact on the loss is understood.
- When to use this? The chain rule is applied in backpropagation to propagate gradients backward through each layer, from the output to the input.
4. Gradient Descent
- Why we need this? Gradient descent is an optimization technique that uses calculus to minimize the loss function. It adjusts model parameters to reduce errors in predictions.
- What the output means? Each iteration provides updated weights that (ideally) bring the model closer to optimal predictions by minimizing the loss function.
- When to use this? Gradient descent is used during model training to iteratively update parameters and improve accuracy by finding the lowest point in the loss landscape.
5. Integrals
- Why we need this? Integrals are less commonly used directly in deep learning, but they are essential for understanding concepts like probability and expectations, which play a role in algorithms like Bayesian methods.
- What the output means? The output of an integral provides the accumulated area under a curve, useful for calculating probabilities and expected values.
- When to use this? Integrals are often used in probabilistic machine learning for modeling distributions and in Bayesian inference.
6. Hessians and Second Derivatives
- Why we need this? Second derivatives, and specifically Hessians (matrices of second derivatives), help determine the curvature of the loss surface, providing insights into whether a point is a local minimum, maximum, or saddle point.
- What the output means? A Hessian matrix shows how curved the loss surface is around a point, indicating the sensitivity of the loss to parameter changes.
- When to use this? Second derivatives are often used in advanced optimization methods (like Newton's method) or when analyzing model stability and convergence.

### Optimization

Local/global minima/maxima
Gradient descent intuition
Learning rate concepts

## Probability & Statistics

### Basic Probability

Probability distributions (especially Normal/Gaussian)
Mean, median, mode
Variance, standard deviation
Covariance and correlation

### Important for ML/DL

Bayes' theorem
Maximum likelihood estimation
Cross-entropy
Information gain
Sampling and random variables
